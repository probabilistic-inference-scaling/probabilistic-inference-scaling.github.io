<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Probabilistic Inference Scaling">
  <meta name="keywords" content="Probabilistic Inference Scaling">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Probabilistic Inference Scaling</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5JX0F75QDW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods</h1>
          <h2 class="title is-6 publlication-title">-----</h2>
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://ishapuri.github.io/">Isha Puri</a><sup>*1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=O71amfMAAAAJ&hl=en&oi=ao">Shivchander Sudalairaj</a><sup>*2</sup>,</span>
            <span class="author-block">
              <a href="https://gxxu-ml.github.io/">GX Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://xuk.ai/">Kai Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://akashgit.github.io/">Akash Srivastava</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>MIT,</span>
            <span class="author-block"><sup>2</sup>Red Hat AI Innovation, MIT-IBM Watson AI Lab</span>
          </div>

          <div class="is-size-7 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              
              <span class="link-block">
                <!-- BELOW SHOULD BE ARXIV LINK -->
                <a href="/Users/ishapuri/Desktop/probabilistic-inference-scaling.github.io/assets/pdf/probabilistic-inference-scaling-paper.pdf"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ishapuri/probabilistic_inference_scaling"
                   class="external-link button is-normal ">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <div style="background-color: #f5f5f5; border-radius: 10px; padding: 20px;">
            <p>
              Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4--16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- Original YouTube embed
          <iframe width="560" height="315" src="https://www.youtube.com/embed/Mja_qM_-jsg?si=uwfF26Zhwmvzib6A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          -->
          <video width="1120" height="630" controls style="margin: 0 auto; display: block; border: 2px solid black;">
            <source src="assets/videos/process_video.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
      </div>
    </div>
    <!--/ Paper video. -->

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Our Results</h2>
        <div class="content has-text-justified">
          <p>
            Our experimental results demonstrate the effectiveness of our probabilistic inference approach to inference-time scaling. The plots above show how our particle-based Monte Carlo methods achieve the following improvements: <br>
              <br>
              • 4-16x better scaling rate compared to deterministic search methods on challenging mathematical reasoning tasks <br>
              • Qwen2.5-Math-1.5B-Instruct surpasses GPT-4 accuracy with only 4 rollouts <br>
              • Qwen2.5-Math-7B-Instruct achieves o1 level accuracy with only 32 rollouts <br>
              <br>
              These results highlight the efficiency and practicality of our method for real-world applications.          </p>
          <style>
            .image-container {
              display: flex;
              justify-content: space-between;
              margin-top: 20px;
            }
            
            .zoom-image {
              width: 32%;
              transition: transform 0.3s ease;
            }
            
            .zoom-image:hover {
              transform: scale(1.2);
              z-index: 1;
            }
          </style>

            <img class="zoom-image" src="assets/images/main_plot_llama_1b.jpg" alt="Result 1" style="width: 75%; display: block; margin: 20px auto;">
            <img class="zoom-image" src="assets/images/main_plot_llama_8b.jpg" alt="Result 2" style="width: 75%; display: block; margin: 20px auto;">
            <img class="zoom-image" src="assets/images/main_plot_qwen_7b_page-0001.jpg" alt="Result 3" style="width: 75%; display: block; margin: 20px auto;">
        </div>
      </div>
    </div>
  </div>
</section>




<script type="text/javascript">
  $(function() {
  var screenWidth = $(window).width();
  if (screenWidth >= 800) {
    $('#gpt-video-1').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#gpt-video-2').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#click-query-icl').attr('autoplay', 'autoplay');
  }
});
</script>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{probabilistic-inference-scaling,
  author    = {Puri, Isha and Sudalairaj, Shivchander and Xu, Guangxuan and Xu, Kai and Srivastava, Akash},
  title     = {A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods 	},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./assets/pdf/probabilistic-inference-scaling-paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/ishapuri/probabilistic_inference_scaling/tree/main" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
        <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies templates, which is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Source Code: <a href="https://github.com/nerfies/nerfies.github.io">Nerfies source code</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
