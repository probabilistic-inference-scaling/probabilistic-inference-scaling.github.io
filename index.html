<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Probabilistic Inference Scaling">
  <meta name="keywords" content="Probabilistic Inference Scaling">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Probabilistic Inference Scaling</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5JX0F75QDW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <div class="columns is-centered"></div>
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Can we use classical probabilistic inference methods to scale small LMs to o1 level?</h1>
        </div>
      </div>
      <br>
      <br>
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods</h1>

          <h1 class="title is-4 publication-title">"particle filtering for inference scaling"</h1>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-one-third has-text-centered">
          <img src="assets/images/logo.png" alt="Logo" style="height: 120px;">
        </div>
        <div class="column is-two-thirds">
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://ishapuri.github.io/">Isha Puri</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=O71amfMAAAAJ&hl=en&oi=ao">Shivchander Sudalairaj</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://gxxu-ml.github.io/">GX Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://xuk.ai/">Kai Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://akashgit.github.io/">Akash Srivastava</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>MIT CSAIL,</span>
            <span class="author-block"><sup>2</sup>Red Hat AI Innovation</span>
          </div>

          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2502.01618"
                 class="external-link button is-normal ">
                <span class="icon">
                    <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/probabilistic-inference-scaling/probabilistic-inference-scaling"
                 class="external-link button is-normal ">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <video 
        width="1120" 
        height="630" 
        controls 
        style="margin: 0 auto; display: block; border: 2px solid black;" 
        poster="assets/images/process_video_cover.jpg">
        <source src="assets/videos/process_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>


  <br><br>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <div style="background-color: #f5f5f5; border-radius: 10px; padding: 20px;">
            <p>
              Large language models (LLMs) have achieved significant performance gains via scaling up model sizes and/or data. However, recent evidence suggests diminishing returns from such approaches, motivating scaling the computation spent at inference time. Existing inference-time scaling methods, usually with reward models, cast the task as a search problem, which tends to be vulnerable to reward hacking as a consequence of approximation errors in reward models. In this paper, we instead cast inference-time scaling as a probabilistic inference task and leverage sampling-based techniques to explore the typical set of the state distribution of a state-space model with an approximate likelihood, rather than optimize for its mode directly. We propose a novel inference-time scaling approach by adapting particle-based Monte Carlo methods to this task. Our empirical evaluation demonstrates that our methods have a 4--16x better scaling rate over our deterministic search counterparts on various challenging mathematical reasoning tasks. Using our approach, we show that Qwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts, while Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts. Our work not only presents an effective method to inference-time scaling, but also connects the rich literature in probabilistic inference with inference-time scaling of LLMs to develop more robust algorithms in future work.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <br>
    <br>
    <br>
    <br>




    <!-- inference scaling. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Wait so ... what is inference-time scaling?</h2>
        <div class="content has-text-justified">
          <div style="background-color: white; border-radius: 0px; padding: 0px;">
            <video 
                width="1120" 
                height="630" 
                controls 
                style="margin: 0 auto; display: block; border: 2px solid black;" 
                poster="assets/images/inference_scaling_coverPhoto.jpg">
                <source src="assets/videos/inference_scaling.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
            <hr style="border-top: 1px solid #ddd; margin: 20px 0;">
            <div style="background-color: #f5f5f5; border-radius: 10px; padding: 20px;">
              <p style="text-align: center;"><strong>So what's wrong with current inference scaling methods?&nbsp;</strong></p>
              <p style="text-align: center;">Well, many current inference scaling methods "guide" their search process with Process Reward Models - off-the-shelf models that take a problem and a (partial or complete) answer and return a reward score. These methods (beam search, DVTS, etc) take the "top-N" options at every step and explore these.&nbsp;</p>
              <p style="text-align: center;">The problem, however, is that PRMs, as in the case of almost all Reward Models, are imperfect. They are often inadequate approximations of the ground truth, and following them leads to&nbsp;<em>Reward Hacking</em>,&nbsp;where the final output is optimized to score well according to the reward model but fails to be useful and/or correct.&nbsp;</p>
              <p style="text-align: center;">This is where our method comes in. We ask the following -&nbsp;</p>
              <p style="text-align: center; color: rgb(56, 10, 56);"><strong>can we propose inference-time scaling as a probabilistic inference task?</strong></p>
            </div>
          </div>
        </div>
      </div>
      
    </div>
    <!--/ inference scaling. -->



    <!-- Paper video. -->
    
    <!--/ Paper video. -->

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Our Method</h2>
        <p>Graphics explaining the process are below. A video detailing the method is at the top of the page.</p>
        <div class="content has-text-justified">

          <img src="assets/images/particle_filtering_figures-cropped.jpg" alt="Process Overview" style="width: 100%; display: block; margin: 20px auto;">

          <img src="assets/images/process_video_cover.jpg" alt="Process Overview" style="width: 100%; display: block; margin: 20px auto;">

          
        </div>
      </div>
    </div>
  </div>
</section>






<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Our Results</h2>
        <div class="content has-text-justified">
          <p>
            <h6>Our experimental results demonstrate the effectiveness of our probabilistic inference approach to inference-time scaling. The plots below show how our particle-based Monte Carlo methods achieve the following improvements: <br>
              <br>
              • <strong>4-16x better scaling rate compared to deterministic search methods on challenging mathematical reasoning tasks</strong> <br>
              • <strong>Qwen2.5-Math-1.5B-Instruct surpasses GPT-4o accuracy with only 4 rollouts</strong> <br>
              • <strong>Qwen2.5-Math-7B-Instruct achieves o1 level accuracy with only 32 rollouts</strong> <br>
              <br>
              These results highlight the efficiency and practicality of our method for real-world applications!</h6>          </p>
          <style>
            .image-container {
              display: flex;
              justify-content: space-between;
              margin-top: 20px;
            }
            
            .zoom-image {
              width: 32%;
              transition: transform 0.3s ease;
            }
            
            .zoom-image:hover {
              transform: scale(1.2);
              z-index: 1;
            }
          </style>
            <div style="display: flex; justify-content: space-between;">
              <div style="width: 48%;">
                <img class="zoom-image" src="assets/images/results_table.png" alt="Results Table" style="width: 100%; height: 100%; object-fit: contain;">
              </div>
              <div style="width: 48%; display: flex; flex-direction: column; justify-content: space-between;">
                <img class="zoom-image" src="assets/images/main_plot_llama_1b.jpg" alt="Result 1" style="width: 100%; height: 32%;">
                <img class="zoom-image" src="assets/images/main_plot_llama_8b.jpg" alt="Result 2" style="width: 100%; height: 32%;">
                <img class="zoom-image" src="assets/images/main_plot_qwen_7b_page-0001.jpg" alt="Result 3" style="width: 100%; height: 32%;">
              </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>




<script type="text/javascript">
  $(function() {
  var screenWidth = $(window).width();
  if (screenWidth >= 800) {
    $('#gpt-video-1').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#gpt-video-2').attr('autoplay', 'autoplay');
  }
  if (screenWidth >= 800) {
    $('#click-query-icl').attr('autoplay', 'autoplay');
  }
});
</script>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre style="background-color: #bbb9b98b; padding: 15px; border-radius: 5px;"><code>@misc{puri2025probabilisticinferenceapproachinferencetime,
      title={A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods}, 
      author={Isha Puri and Shivchander Sudalairaj and Guangxuan Xu and Kai Xu and Akash Srivastava},
      year={2025},
      eprint={2502.01618},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.01618}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2502.01618">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/ishapuri/probabilistic_inference_scaling/tree/main" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
        <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website adapted from the Nerfies templates, which is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Source Code: <a href="https://github.com/nerfies/nerfies.github.io">Nerfies source code</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>